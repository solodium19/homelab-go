## AutoScalling in k8s
Теперь поговорим про автоскеллинг, я давненько уже изучил эту тему и есть понимание про HPA,VPA,PPA, но последнии два довольно специфичны, а вот первый очень нам нужен, однако у него есть тонкости своей настройки, чтобы собирать метрики - нужен сервер метрик, чтобы собирать кастомные метрики - нужны адаптеры, на помощь нам приходит Keda, этот малый содержит в себе уже это всё, и на основе своих манифестов под капотом создаёт HPA, но без доп настроек. Установим его

# Установка keda helm
```bash
helm repo add kedacore https://kedacore.github.io/charts

helm install keda kedacore/keda --namespace keda --create-namespace --version 2.16.1
```

# Создание манифеста скалирования для нашего объёкта

Немножко отвлечёмся на саму Кеду, этот парень может скалировать не только по метрикам, а по таймеру(cron), по событиям. Под капотом имеет:
Operator KEDA - контролирует и согласует скейлинг(Мозг)
Metrics Server KEDA - специализированный сервер метрик и предоставляет внешние метрики
Webhooks admission - обеспечивает в объектах настройки
TriggerAuthentication - хранит учётные данные
Scaler - сопоставляет тригеры с событиями
ScaledObject - поведение масштабирования
CloudEventSource - вычитывание из облаков

# Теперь создаём scaled object
```bash
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: app-deploy-autoscale
  namespace: prod
spec:
  scaleTargetRef: # Указываем что именно хотим скалировать
    name: vote-app-deployment
    kind: Deployment

  minReplicaCount: 1 # Мин.Кол-во реплик    
  maxReplicaCount: 20 # Макс.Кол-во реплик

  cooldownPeriod: 300       # 300 сек перед уменьшением кол-ва реплик
  pollingInterval: 15       # Как часто кеда опрашивает наши метрики(по дефолту 15сек как и HPA, можем поменять при необходимости)

  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0 # Окно стабилизации здесь 0 сек, т.е кол-во подов будет расти без подтверждения времени
          policies:
          - type: Pods
            value: 4            # +4 пода за шаг каждые 15сек если нагрузка растёт
            periodSeconds: 15
        scaleDown:
          stabilizationWindowSeconds: 300   # подтверждение падения 300 сек, кол-во подов будет уменьшаться только если в течении 300секунд метрики будут ниже указанного нами уровня
          policies:
          - type: Pods
            value: 2            # -2 пода за шаг каждые 15сек если нагрузка падает(но у нас есть окностабилизации, которое не даст рушить скаллинг поды каждые 15 сек, он будет ждать 300секунд, рушить поды, потом через 15сек опять захочет сломать, но будет ждать ещё 300сек)
            periodSeconds: 15
# P.S Методика скалирования выбрана не случайна, у нас выбран метод жесткого скалирования вверх и медленного скаллирования вниз для того, чтобы наше приложение было более пользовательско-приветственное и они имели к нему быстрый доступ
  triggers:
    - type: cpu
      metricType: Utilization
      metadata:
        value: "75"   # если >75% — скейлимся
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-operated.monitoring.svc:9090 # здесь указываем куда пойдем за метриками
        query: |
          sum(rate(http_requests_total{app="app-deploy"}[1m])) # указываем саму метрики
        threshold: "100"  # например: если > 100 http запросов в минуту, то скелимся
```

После этого наш объект создан, и будем каждые 15 секунд обновлять указанные метрики и при необходимости скелится

# Для закрепления можем настроить скалирование например для нашего гитлаб раннера, и скажем ему, что в момент рабочего дня 8 - 17 нам нужно 3 реплики, чтобы было по кайфу запускаться и не ждать, а вот в нерабочее время только 1, чтобы ночью собирались билды, но их не много и 1 раннера нам хватит(p.s это просто пример, скалирования раннеров не всегда обязательно, ибо мы их используем в кубере и они просто создают поды с Job, а создавать они могут не один за раз)
```bash
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
 name: ScaledObject
spec:
 scaleTargetRef:
  name: gitlab-runner
 minReplicaCount: 1
 triggers:
 - type: cron
   metadata:
    timezone: Europe/Moscow
    start: "0 8 * * *"
    end: "0 17 * * *"
    desiredReplicas: "3"
```
